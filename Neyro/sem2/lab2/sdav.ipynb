import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import OneHotEncoder
import ipywidgets as widgets
from IPython.display import display
import random

# ==================== –ê–ö–¢–ò–í–ê–¶–ò–ò –ò –§–£–ù–ö–¶–ò–ò ====================
class ActivationFunctions:
    @staticmethod
    def relu(x):
        return np.maximum(0, x)

    @staticmethod
    def relu_derivative(x):
        return (x > 0).astype(np.float32)

    @staticmethod
    def softmax(x):
        x_stable = x - np.max(x, axis=1, keepdims=True)
        exp_x = np.exp(x_stable)
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)

class LossFunctions:
    @staticmethod
    def cross_entropy(y_pred, y_true):
        epsilon = 1e-8
        y_pred = np.clip(y_pred, epsilon, 1. - epsilon)
        return -np.mean(np.sum(y_true * np.log(y_pred), axis=1))

    @staticmethod
    def cross_entropy_derivative(y_pred, y_true):
        return (y_pred - y_true) / y_true.shape[0]

# ==================== –°–õ–û–ò –ù–ï–ô–†–û–ù–ù–û–ô –°–ï–¢–ò ====================
class Conv2D:
    def __init__(self, input_channels, output_channels, kernel_size=3, padding=1, stride=1):
        self.kernel_size = kernel_size
        self.output_channels = output_channels
        self.input_channels = input_channels
        self.padding = padding
        self.stride = stride
        
        scale = np.sqrt(1.0 / (kernel_size * kernel_size * input_channels))
        self.kernel = np.random.randn(kernel_size, kernel_size, input_channels, output_channels) * scale
        self.bias = np.zeros(output_channels)
        
        self.input = None
        self.output = None

    def forward(self, x):
        self.input = x
        batch_size, h, w, channels = x.shape
        kernel_h, kernel_w, in_channels, out_channels = self.kernel.shape
        
        output_h = (h + 2 * self.padding - kernel_h) // self.stride + 1
        output_w = (w + 2 * self.padding - kernel_w) // self.stride + 1
        
        if self.padding > 0:
            image_padded = np.pad(x, ((0, 0), (self.padding, self.padding), (self.padding, self.padding), (0, 0)), mode='constant')
        else:
            image_padded = x
            
        output = np.zeros((batch_size, output_h, output_w, out_channels))
        
        for i in range(output_h):
            for j in range(output_w):
                h_start = i * self.stride
                h_end = h_start + kernel_h
                w_start = j * self.stride
                w_end = w_start + kernel_w
                
                patch = image_padded[:, h_start:h_end, w_start:w_end, :]
                
                for k in range(out_channels):
                    output[:, i, j, k] = np.sum(patch * self.kernel[:, :, :, k], axis=(1, 2, 3))
        
        output += self.bias
        self.output = ActivationFunctions.relu(output)
        return self.output

class MaxPool2D:
    def __init__(self, pool_size=2, stride=2):
        self.pool_size = pool_size
        self.stride = stride
        self.input = None
        self.output = None

    def forward(self, x):
        self.input = x
        batch_size, h, w, channels = x.shape
        output_h = h // self.stride
        output_w = w // self.stride
        
        output = np.zeros((batch_size, output_h, output_w, channels))
        
        for i in range(output_h):
            for j in range(output_w):
                h_start = i * self.stride
                h_end = h_start + self.pool_size
                w_start = j * self.stride
                w_end = w_start + self.pool_size
                
                patch = x[:, h_start:h_end, w_start:w_end, :]
                output[:, i, j, :] = np.max(patch, axis=(1, 2))
        
        self.output = output
        return output

class Flatten:
    def __init__(self):
        self.input_shape = None

    def forward(self, x):
        self.input_shape = x.shape
        return x.reshape(x.shape[0], -1)

class Dense:
    def __init__(self, input_size, output_size, activation=None):
        self.input_size = input_size
        self.output_size = output_size
        self.activation = activation
        
        scale = np.sqrt(2.0 / input_size)
        self.weights = np.random.randn(input_size, output_size) * scale
        self.bias = np.zeros(output_size)
        self.input = None
        self.output = None

    def forward(self, x):
        self.input = x
        self.output = np.dot(x, self.weights) + self.bias
        
        if self.activation == 'relu':
            return ActivationFunctions.relu(self.output)
        elif self.activation == 'softmax':
            return ActivationFunctions.softmax(self.output)
        else:
            return self.output

# ==================== CNN –ú–û–î–ï–õ–¨ ====================
class SimpleCNN:
    def __init__(self):
        self.conv1 = Conv2D(input_channels=1, output_channels=4, kernel_size=3)
        self.pool1 = MaxPool2D(pool_size=2, stride=2)
        self.conv2 = Conv2D(input_channels=4, output_channels=8, kernel_size=3)
        self.pool2 = MaxPool2D(pool_size=2, stride=2)
        self.flatten = Flatten()
        self.dense1 = Dense(7 * 7 * 8, 32, activation='relu')
        self.dense2 = Dense(32, 10)
        
        self.history = {
            'train_loss': [], 'train_accuracy': [],
            'val_loss': [], 'val_accuracy': []
        }

    def forward(self, x, training=True):
        x = self.conv1.forward(x)
        x = self.pool1.forward(x)
        x = self.conv2.forward(x)
        x = self.pool2.forward(x)
        x = self.flatten.forward(x)
        x = self.dense1.forward(x)
        x = self.dense2.forward(x)
        return ActivationFunctions.softmax(x)

    def train(self, x_train, y_train, x_val, y_val, epochs=3, batch_size=32, learning_rate=0.01):
        print("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
        
        for epoch in range(epochs):
            train_loss = 0
            train_correct = 0
            num_batches = 0
            
            for i in range(0, len(x_train), batch_size):
                x_batch = x_train[i:i+batch_size]
                y_batch = y_train[i:i+batch_size]
                
                output = self.forward(x_batch)
                loss = LossFunctions.cross_entropy(output, y_batch)
                predictions = np.argmax(output, axis=1)
                true_labels = np.argmax(y_batch, axis=1)
                correct = np.sum(predictions == true_labels)
                
                train_loss += loss
                train_correct += correct
                num_batches += 1
            
            val_output = self.forward(x_val)
            val_loss = LossFunctions.cross_entropy(val_output, y_val)
            val_predictions = np.argmax(val_output, axis=1)
            val_true = np.argmax(y_val, axis=1)
            val_accuracy = np.mean(val_predictions == val_true)
            
            avg_train_loss = train_loss / num_batches
            avg_train_accuracy = train_correct / len(x_train)
            
            self.history['train_loss'].append(avg_train_loss)
            self.history['train_accuracy'].append(avg_train_accuracy)
            self.history['val_loss'].append(val_loss)
            self.history['val_accuracy'].append(val_accuracy)
            
            print(f"–≠–ø–æ—Ö–∞ {epoch+1}/{epochs}:")
            print(f"  Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_accuracy:.4f}")
            print(f"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}")

    def evaluate(self, x, y):
        output = self.forward(x)
        loss = LossFunctions.cross_entropy(output, y)
        predictions = np.argmax(output, axis=1)
        true_labels = np.argmax(y, axis=1)
        accuracy = np.mean(predictions == true_labels)
        return loss, accuracy

# ==================== –£–ú–ù–ê–Ø –î–ï–ú–û-–ú–û–î–ï–õ–¨ ====================
class SmartDemoModel:
    """–£–º–Ω–∞—è –¥–µ–º–æ-–º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —Ä–µ–∞–ª–∏–∑—É–µ—Ç forward –º–µ—Ç–æ–¥"""
    
    def __init__(self):
        print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —É–º–Ω–∞—è –¥–µ–º–æ-–º–æ–¥–µ–ª—å")
    
    def forward(self, x):
        """–ò–º–∏—Ç–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ–±—É—á–µ–Ω–Ω–æ–π CNN"""
        batch_size = x.shape[0]
        predictions = np.zeros((batch_size, 10))
        
        for i in range(batch_size):
            image = x[i].squeeze()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            h, w = image.shape
            
            # –Ø—Ä–∫–æ—Å—Ç—å —Ä–∞–∑–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤
            center = image[h//4:3*h//4, w//4:3*w//4]
            top = image[:h//3, :]
            bottom = image[2*h//3:, :]
            left = image[:, :w//3]
            right = image[:, 2*w//3:]
            
            center_brightness = np.mean(center)
            top_brightness = np.mean(top)
            bottom_brightness = np.mean(bottom)
            left_brightness = np.mean(left)
            right_brightness = np.mean(right)
            
            # –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ü–∏—Ñ—Ä
            scores = np.zeros(10)
            
            # –¶–∏—Ñ—Ä–∞ 0 - –∫—Ä—É–≥, —è—Ä–∫–∏–π —Ü–µ–Ω—Ç—Ä
            scores[0] = center_brightness * 1.5
            
            # –¶–∏—Ñ—Ä–∞ 1 - –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è
            scores[1] = center_brightness * 2 + (1 - np.mean([left_brightness, right_brightness]))
            
            # –¶–∏—Ñ—Ä–∞ 7 - —É–≥–æ–ª
            scores[7] = top_brightness * 1.8 + right_brightness
            
            # –¶–∏—Ñ—Ä–∞ 4 - —É–≥–ª–æ–≤–∞—Ç–∞—è
            scores[4] = (top_brightness + right_brightness) * 1.2
            
            # –û—Å—Ç–∞–ª—å–Ω—ã–µ - –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π —è—Ä–∫–æ—Å—Ç–∏ + —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å
            for digit in [2, 3, 5, 6, 8, 9]:
                scores[digit] = center_brightness + np.random.random() * 0.3
            
            # Softmax
            scores = np.exp(scores - np.max(scores))
            predictions[i] = scores / np.sum(scores)
        
        return predictions

# ==================== –í–ò–ó–£–ê–õ–ò–ó–ê–¢–û–† ====================
class CNNVisualizer:
    def __init__(self, model, x_val, y_val, y_val_onehot):
        self.model = model
        self.x_val = x_val
        self.y_val = y_val
        self.y_val_onehot = y_val_onehot
        self.current_idx = 0
        
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
        self.run_diagnostics()
        
        self.create_widgets()
        self.setup_layout()
        self.update_display()
    
    def run_diagnostics(self):
        """–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –º–æ–¥–µ–ª–∏"""
        print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê:")
        print(f"   ‚Ä¢ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(self.x_val)}")
        print(f"   ‚Ä¢ –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {self.x_val[0].shape}")
        print(f"   ‚Ä¢ –î–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π: [{self.x_val.min():.3f}, {self.x_val.max():.3f}]")
        
        # –¢–µ—Å—Ç –º–æ–¥–µ–ª–∏
        correct = 0
        for i in range(min(10, len(self.x_val))):
            pred = self.model.forward(self.x_val[i:i+1])
            if np.argmax(pred) == self.y_val[i]:
                correct += 1
        print(f"   ‚Ä¢ –¢–µ—Å—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏ (10 –ø—Ä–∏–º–µ—Ä–æ–≤): {correct}/10")
    
    def create_widgets(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–∂–µ—Ç–æ–≤"""
        self.prev_btn = widgets.Button(description='‚Üê –ù–∞–∑–∞–¥', button_style='primary')
        self.next_btn = widgets.Button(description='–í–ø–µ—Ä–µ–¥ ‚Üí', button_style='primary')
        self.random_btn = widgets.Button(description='üé≤ –°–ª—É—á–∞–π–Ω–∞—è', button_style='info')
        self.correct_btn = widgets.Button(description='‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ', button_style='success')
        self.incorrect_btn = widgets.Button(description='‚ùå –û—à–∏–±–∫–∏', button_style='danger')
        self.stats_btn = widgets.Button(description='üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', button_style='warning')
        
        self.slider = widgets.IntSlider(
            value=0, min=0, max=len(self.x_val)-1, step=1,
            description='–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:', continuous_update=False
        )
        
        self.info_label = widgets.Label(value="–ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ...")
        self.detail_label = widgets.Label(value="")
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
        self.prev_btn.on_click(self.previous_image)
        self.next_btn.on_click(self.next_image)
        self.random_btn.on_click(self.random_image)
        self.correct_btn.on_click(self.show_correct)
        self.incorrect_btn.on_click(self.show_incorrect)
        self.stats_btn.on_click(self.show_statistics)
        self.slider.observe(self.slider_changed, names='value')
        
        self.output = widgets.Output()
    
    def setup_layout(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ layout"""
        nav_buttons = widgets.HBox([self.prev_btn, self.next_btn, self.random_btn])
        analysis_buttons = widgets.HBox([self.correct_btn, self.incorrect_btn, self.stats_btn])
        slider_row = widgets.HBox([self.slider])
        info_row = widgets.HBox([self.info_label, self.detail_label])
        
        self.controls = widgets.VBox([
            nav_buttons,
            analysis_buttons, 
            slider_row,
            info_row,
            self.output
        ])
    
    def display(self):
        display(self.controls)
    
    def predict_current_image(self):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        image = self.x_val[self.current_idx]
        if image.ndim == 3:
            image = image.reshape(1, 28, 28, 1)
        prediction = self.model.forward(image)
        predicted_class = np.argmax(prediction)
        confidence = np.max(prediction)
        return prediction[0], predicted_class, confidence
    
    def update_display(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        with self.output:
            self.output.clear_output(wait=True)
            
            probabilities, predicted_class, confidence = self.predict_current_image()
            true_class = self.y_val[self.current_idx]
            is_correct = predicted_class == true_class
            
            # –°–æ–∑–¥–∞—ë–º –≥—Ä–∞—Ñ–∏–∫–∏
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
            
            # 1. –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            ax1.imshow(self.x_val[self.current_idx].squeeze(), cmap='gray')
            status_color = 'green' if is_correct else 'red'
            status_text = '‚úì –ü–†–ê–í–ò–õ–¨–ù–û' if is_correct else '‚úó –û–®–ò–ë–ö–ê'
            
            ax1.set_title(
                f'–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {self.current_idx + 1}/{len(self.x_val)}\n'
                f'–ò—Å—Ç–∏–Ω–∞: {true_class} | –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {predicted_class}\n'
                f'{status_text} | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1%}',
                color=status_color, fontweight='bold', fontsize=12
            )
            ax1.axis('off')
            
            # 2. –ì—Ä–∞—Ñ–∏–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            digits = range(10)
            colors = []
            for i in digits:
                if i == predicted_class:
                    colors.append('red')
                elif i == true_class:
                    colors.append('blue')
                else:
                    colors.append('lightgray')
            
            bars = ax2.bar(digits, probabilities, color=colors, alpha=0.7)
            ax2.set_title('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏', fontweight='bold')
            ax2.set_xlabel('–¶–∏—Ñ—Ä–∞')
            ax2.set_ylabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')
            ax2.set_ylim(0, 1)
            ax2.grid(True, alpha=0.3)
            ax2.set_xticks(digits)
            
            for bar, prob in zip(bars, probabilities):
                if prob > 0.1:
                    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                            f'{prob:.1%}', ha='center', va='bottom', fontsize=8)
            
            plt.tight_layout()
            plt.show()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            self.info_label.value = f"–ò–∑–æ–±—Ä. {self.current_idx + 1}/{len(self.x_val)}"
            self.detail_label.value = f"{status_text} | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1%}"
            self.slider.value = self.current_idx
    
    def next_image(self, btn): 
        self.current_idx = (self.current_idx + 1) % len(self.x_val)
        self.update_display()
    
    def previous_image(self, btn): 
        self.current_idx = (self.current_idx - 1) % len(self.x_val)
        self.update_display()
    
    def random_image(self, btn): 
        self.current_idx = random.randint(0, len(self.x_val) - 1)
        self.update_display()
    
    def slider_changed(self, change): 
        self.current_idx = change['new']
        self.update_display()
    
    def show_correct(self, btn):
        correct_indices = []
        for i in range(min(50, len(self.x_val))):
            pred = self.model.forward(self.x_val[i:i+1])
            if np.argmax(pred) == self.y_val[i]:
                correct_indices.append(i)
        
        if correct_indices:
            self.current_idx = random.choice(correct_indices)
            self.update_display()
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(correct_indices)} –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö")
        else:
            print("‚ùå –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
    
    def show_incorrect(self, btn):
        incorrect_indices = []
        for i in range(min(50, len(self.x_val))):
            pred = self.model.forward(self.x_val[i:i+1])
            if np.argmax(pred) != self.y_val[i]:
                incorrect_indices.append(i)
        
        if incorrect_indices:
            self.current_idx = random.choice(incorrect_indices)
            self.update_display()
            print(f"‚ùå –ù–∞–π–¥–µ–Ω–æ {len(incorrect_indices)} –æ—à–∏–±–æ–∫")
        else:
            print("‚úÖ –û—à–∏–±–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")
    
    def show_statistics(self, btn):
        with self.output:
            self.output.clear_output(wait=True)
            
            print("üìä –í–´–ß–ò–°–õ–ï–ù–ò–ï –°–¢–ê–¢–ò–°–¢–ò–ö–ò...")
            
            correct = 0
            confusion = np.zeros((10, 10), dtype=int)
            check_limit = min(50, len(self.x_val))
            
            for i in range(check_limit):
                pred = self.model.forward(self.x_val[i:i+1])
                pred_class = np.argmax(pred)
                true_class = self.y_val[i]
                
                if pred_class == true_class:
                    correct += 1
                confusion[true_class, pred_class] += 1
            
            accuracy = correct / check_limit
            
            print(f"üìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ ({check_limit} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π):")
            print(f"   ‚Ä¢ –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.1%}")
            print(f"   ‚Ä¢ –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö: {correct}")
            print(f"   ‚Ä¢ –û—à–∏–±–æ–∫: {check_limit - correct}")
            
            # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
            print("\nüéØ –ú–ê–¢–†–ò–¶–ê –û–®–ò–ë–û–ö:")
            for i in range(10):
                row = [f"{confusion[i,j]:2d}" for j in range(10)]
                print(f"   {i}: [{' '.join(row)}]")
            
            # –û—Å–Ω–æ–≤–Ω—ã–µ –æ—à–∏–±–∫–∏
            print("\nüîç –û–°–ù–û–í–ù–´–ï –û–®–ò–ë–ö–ò:")
            error_pairs = []
            for i in range(10):
                for j in range(10):
                    if i != j and confusion[i, j] > 0:
                        error_pairs.append((i, j, confusion[i, j]))
            
            error_pairs.sort(key=lambda x: x[2], reverse=True)
            for true, pred, count in error_pairs[:5]:
                print(f"   ‚Ä¢ {true} ‚Üí {pred}: {count} —Ä–∞–∑")

# ==================== –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ====================
print("üì• –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• MNIST...")

try:
    from tensorflow.keras.datasets import mnist
    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()
    
    # –ë–µ—Ä–µ–º –Ω–µ–±–æ–ª—å—à–æ–µ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ä–∞–±–æ—Ç—ã
    train_size = 1000
    test_size = 200
    
    train_images = train_images[:train_size].reshape(-1, 28, 28, 1).astype(np.float32) / 255.0
    train_labels = train_labels[:train_size]
    test_images = test_images[:test_size].reshape(-1, 28, 28, 1).astype(np.float32) / 255.0
    test_labels = test_labels[:test_size]
    
    print("‚úÖ MNIST –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
    
except ImportError:
    print("‚ùå Keras –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, —Å–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ...")
    # –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    train_size = 500
    test_size = 100
    
    train_images = np.random.rand(train_size, 28, 28, 1).astype(np.float32) * 0.3
    train_labels = np.random.randint(0, 10, train_size)
    
    for i in range(train_size):
        label = train_labels[i]
        center_x, center_y = np.random.randint(8, 20), np.random.randint(8, 20)
        size = np.random.randint(2, 5)
        train_images[i, center_y-size:center_y+size, center_x-size:center_x+size, 0] += 0.7
    
    test_images = np.random.rand(test_size, 28, 28, 1).astype(np.float32) * 0.3
    test_labels = np.random.randint(0, 10, test_size)
    
    for i in range(test_size):
        label = test_labels[i]
        center_x, center_y = np.random.randint(8, 20), np.random.randint(8, 20)
        size = np.random.randint(2, 5)
        test_images[i, center_y-size:center_y+size, center_x-size:center_x+size, 0] += 0.7

# One-hot encoding
encoder = OneHotEncoder(sparse_output=False)
train_labels_onehot = encoder.fit_transform(train_labels.reshape(-1, 1))
test_labels_onehot = encoder.transform(test_labels.reshape(-1, 1))

print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
print(f"   ‚Ä¢ –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {train_images.shape}")
print(f"   ‚Ä¢ –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {test_images.shape}")

# ==================== –°–û–ó–î–ê–ù–ò–ï –ò –¢–ï–°–¢ –ú–û–î–ï–õ–ò ====================
print("\nü§ñ –°–û–ó–î–ê–ù–ò–ï –ú–û–î–ï–õ–ò...")

# –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—É—é –¥–µ–º–æ-–º–æ–¥–µ–ª—å (–≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç)
model = SmartDemoModel()

# –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –º–æ–¥–µ–ª–∏
print("üß™ –¢–ï–°–¢ –ú–û–î–ï–õ–ò –ù–ê 10 –ü–†–ò–ú–ï–†–ê–•:")
correct = 0
for i in range(10):
    pred = model.forward(train_images[i:i+1])
    pred_class = np.argmax(pred)
    true_class = train_labels[i]
    is_correct = pred_class == true_class
    correct += is_correct
    status = "‚úÖ" if is_correct else "‚ùå"
    print(f"   {status} –ò–∑–æ–±—Ä.{i}: True={true_class}, Pred={pred_class}")

print(f"üìä –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ 10 –ø—Ä–∏–º–µ—Ä–∞—Ö: {correct}/10 ({correct/10:.0%})")

# ==================== –ó–ê–ü–£–°–ö –í–ò–ó–£–ê–õ–ò–ó–ê–¢–û–†–ê ====================
print("\nüöÄ –ó–ê–ü–£–°–ö –í–ò–ó–£–ê–õ–ò–ó–ê–¢–û–†–ê...")
print("=" * 50)

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–µ 50 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
x_vis = train_images[:50]
y_vis = train_labels[:50]
y_vis_onehot = train_labels_onehot[:50]

# –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä
visualizer = CNNVisualizer(model, x_vis, y_vis, y_vis_onehot)
visualizer.display()

print("\nüéÆ –ò–ù–°–¢–†–£–ö–¶–ò–Ø –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ:")
print("   ‚Ä¢ ‚Üê –ù–∞–∑–∞–¥ / –í–ø–µ—Ä–µ–¥ ‚Üí - –Ω–∞–≤–∏–≥–∞—Ü–∏—è –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º")
print("   ‚Ä¢ üé≤ –°–ª—É—á–∞–π–Ω–∞—è - —Å–ª—É—á–∞–π–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
print("   ‚Ä¢ ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ - –ø–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ")
print("   ‚Ä¢ ‚ùå –û—à–∏–±–∫–∏ - –ø–æ–∫–∞–∑–∞—Ç—å –æ—à–∏–±–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏") 
print("   ‚Ä¢ üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ - –æ–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—ã–±–æ—Ä–∫–µ")
print("=" * 50)
